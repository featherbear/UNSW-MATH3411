<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on MATH3411 Musings</title><link>/post/</link><description>Recent content in Posts on MATH3411 Musings</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Andrew Wong (z5206677)</copyright><lastBuildDate>Tue, 26 Nov 2019 16:41:23 +1100</lastBuildDate><atom:link href="/post/index.xml" rel="self" type="application/rss+xml"/><item><title>Arithmetic Coding</title><link>/post/arithmetic-coding/</link><pubDate>Tue, 26 Nov 2019 16:41:23 +1100</pubDate><guid>/post/arithmetic-coding/</guid><description>Arithmetic coding uses fractional decimals (between 0.</description></item><item><title>LZ78 Compression</title><link>/post/lz78-compression/</link><pubDate>Tue, 26 Nov 2019 16:35:42 +1100</pubDate><guid>/post/lz78-compression/</guid><description>LZ78 is a lossless compression algorithm to reduce the size of a repetitive string.</description></item><item><title>Markov Huffman Source</title><link>/post/markov-huffman-source/</link><pubDate>Tue, 26 Nov 2019 16:22:52 +1100</pubDate><guid>/post/markov-huffman-source/</guid><description>In a Markov Source for Huffman codes&amp;hellip;</description></item><item><title>Memory/Markov Sources</title><link>/post/memory-markov-sources/</link><pubDate>Tue, 26 Nov 2019 16:20:21 +1100</pubDate><guid>/post/memory-markov-sources/</guid><description>$M$ is the transition matrix</description></item><item><title>Codeword Extensions</title><link>/post/codeword-extensions/</link><pubDate>Tue, 26 Nov 2019 16:15:20 +1100</pubDate><guid>/post/codeword-extensions/</guid><description>When dealing with single codewords, we can find the average length of a codeword.</description></item><item><title>Comma Codes</title><link>/post/comma-codes/</link><pubDate>Tue, 26 Nov 2019 16:10:39 +1100</pubDate><guid>/post/comma-codes/</guid><description>Comma codes are codes with a common suffix that acts as a delimiter.</description></item><item><title>Kraft McMillan Theorem</title><link>/post/kraft-mcmillan-theorem/</link><pubDate>Tue, 26 Nov 2019 15:58:00 +1100</pubDate><guid>/post/kraft-mcmillan-theorem/</guid><description>The Kraft-McMillan theorem verifies the possible codeword lengths of a given radix.</description></item><item><title>UD Codes</title><link>/post/ud-codes/</link><pubDate>Tue, 26 Nov 2019 15:43:50 +1100</pubDate><guid>/post/ud-codes/</guid><description>UD codes can only be interpreted in one way.</description></item><item><title>Binary Channel</title><link>/post/binary-channel/</link><pubDate>Tue, 26 Nov 2019 14:54:59 +1100</pubDate><guid>/post/binary-channel/</guid><description>H(A, B ) =&amp;gt; Union I(A, B ) =&amp;gt; Intersection</description></item><item><title>Primitive Elements</title><link>/post/primitive-elements/</link><pubDate>Tue, 26 Nov 2019 12:29:58 +1100</pubDate><guid>/post/primitive-elements/</guid><description>Primitive elements in a Galois Field / $Z_p$ An element is primitive in a space $Z_p$, if it can be used to generate every number through its powers (mod p).</description></item><item><title>Units</title><link>/post/units/</link><pubDate>Tue, 26 Nov 2019 12:15:43 +1100</pubDate><guid>/post/units/</guid><description>The units of a number space Z_n, are the set of elements which are invertible.</description></item><item><title>Euler&#39;s Totient</title><link>/post/eulers-totient/</link><pubDate>Tue, 26 Nov 2019 12:13:11 +1100</pubDate><guid>/post/eulers-totient/</guid><description>Euler&amp;rsquo;s Totient / Phi of $n$ calculates the number of units of a given number space $n$</description></item><item><title>Pseudo Primes</title><link>/post/pseudo-primes/</link><pubDate>Tue, 26 Nov 2019 12:12:43 +1100</pubDate><guid>/post/pseudo-primes/</guid><description>Given $gcd(a,n) = 1$, we need to prove that a^(n-1) === 1 mod n.</description></item><item><title>Order</title><link>/post/ord/</link><pubDate>Tue, 26 Nov 2019 12:08:35 +1100</pubDate><guid>/post/ord/</guid><description>The order $k$ of a number $\beta$ in $Z_n$ is the smallest power where $\beta^k mod n === 1$</description></item><item><title>Inverses</title><link>/post/inverses/</link><pubDate>Tue, 26 Nov 2019 12:08:32 +1100</pubDate><guid>/post/inverses/</guid><description>The inverse of a number $b$ in $Z_n$ is a number $a$ such that $ab mod n === 1$</description></item><item><title>Primitive Roots in Polynomial Space</title><link>/post/primitive-roots-in-polynomial-space/</link><pubDate>Tue, 26 Nov 2019 11:55:04 +1100</pubDate><guid>/post/primitive-roots-in-polynomial-space/</guid><description>This question sucks.</description></item><item><title>Fermat Factorisation</title><link>/post/fermat-factorisation/</link><pubDate>Tue, 26 Nov 2019 11:41:19 +1100</pubDate><guid>/post/fermat-factorisation/</guid><description>Fermat Factorisation The Fermat factorisation is a method to find the factors of a large number.</description></item><item><title>Shannon-Fano Codes</title><link>/post/shannon-fano-codes/</link><pubDate>Tue, 26 Nov 2019 11:28:54 +1100</pubDate><guid>/post/shannon-fano-codes/</guid><description>Each codeword has a length of $\ceil(-\log(p_i))$.</description></item><item><title>Crypto</title><link>/post/crypto/</link><pubDate>Wed, 13 Nov 2019 13:47:13 +1100</pubDate><guid>/post/crypto/</guid><description>Caesar Cipher - Simple modulo rotation of each letter ABCD -&amp;gt;3-&amp;gt; DEFG Monoalphabetic substitution cipher ABAB -&amp;gt;XY-&amp;gt; XYXY Transposition cipher HELLO -&amp;gt;2-&amp;gt; LOHEL Vigenere cipher HELLO -&amp;gt;SECRET-&amp;gt; ZINCS One-time pad / Vernam cipher OP.</description></item><item><title>20191105</title><link>/post/20191105/</link><pubDate>Tue, 05 Nov 2019 12:07:20 +1100</pubDate><guid>/post/20191105/</guid><description>// Chapter 5</description></item><item><title>Lecture 12</title><link>/post/lec12/</link><pubDate>Tue, 29 Oct 2019 12:18:42 +1100</pubDate><guid>/post/lec12/</guid><description>The order of an element a in U_m is ord_m(a) = min{i in Z+ : a^i = 1}</description></item><item><title>Lecture 11</title><link>/post/lec11/</link><pubDate>Fri, 25 Oct 2019 14:00:00 +1100</pubDate><guid>/post/lec11/</guid><description>Channel capacity $C = C(A,B) = max I(A,B)$</description></item><item><title>Lecture 10</title><link>/post/lec10/</link><pubDate>Tue, 22 Oct 2019 12:22:34 +1100</pubDate><guid>/post/lec10/</guid><description>Entropy of Extensions</description></item><item><title>Lecture Nine</title><link>/post/lec09/</link><pubDate>Tue, 15 Oct 2019 12:06:28 +1100</pubDate><guid>/post/lec09/</guid><description>Chapter Four - Information Theory Let $I(p)$ be the amount of information given by an event of probability $p$.</description></item><item><title>Lecture 08</title><link>/post/lec08/</link><pubDate>Fri, 11 Oct 2019 14:00:27 +1100</pubDate><guid>/post/lec08/</guid><description>Block symbols - combining multiple symbols</description></item><item><title>Huffman Codes</title><link>/post/huffman-codes/</link><pubDate>Tue, 08 Oct 2019 12:24:13 +1100</pubDate><guid>/post/huffman-codes/</guid><description>Huffman&amp;rsquo;s Algorithm The Huffman coding scheme generates the best possible uniquely decodable code.</description></item><item><title>Lecture Seven</title><link>/post/lec07/</link><pubDate>Tue, 08 Oct 2019 12:24:13 +1100</pubDate><guid>/post/lec07/</guid><description>Optimising Codeword Efficiency Evaluating Usage Add the usage of the leaf nodes.</description></item><item><title>Practice Test 1</title><link>/post/test01/</link><pubDate>Mon, 07 Oct 2019 16:43:45 +1100</pubDate><guid>/post/test01/</guid><description/></item><item><title>Lecture Six</title><link>/post/lec06/</link><pubDate>Fri, 04 Oct 2019 14:03:38 +1000</pubDate><guid>/post/lec06/</guid><description>Chapter Three - Compression Coding Variable length codes Assume there is no channel noise - source coding</description></item><item><title>Lecture 05</title><link>/post/lec05/</link><pubDate>Tue, 01 Oct 2019 12:08:30 +1000</pubDate><guid>/post/lec05/</guid><description>A linear code $C$ is a vector space over some field $F$.</description></item><item><title>Lecture 04</title><link>/post/lec04/</link><pubDate>Fri, 27 Sep 2019 14:09:41 +1000</pubDate><guid>/post/lec04/</guid><description>C = {Hello, Help!</description></item><item><title>Lecture 03</title><link>/post/lec03/</link><pubDate>Tue, 24 Sep 2019 12:17:21 +1000</pubDate><guid>/post/lec03/</guid><description>Binary Hamming error-correction A code $C$ that</description></item><item><title>Tutorial 01</title><link>/post/tut01/</link><pubDate>Thu, 19 Sep 2019 16:04:34 +1000</pubDate><guid>/post/tut01/</guid><description>Question One a.</description></item><item><title>Basic Probability Revision</title><link>/post/basic-probability-revision/</link><pubDate>Tue, 17 Sep 2019 12:20:57 +1000</pubDate><guid>/post/basic-probability-revision/</guid><description>Probability Bayes&amp;rsquo; Rule More</description></item><item><title>Introduction to Codes</title><link>/post/lec01/</link><pubDate>Tue, 17 Sep 2019 12:20:57 +1000</pubDate><guid>/post/lec01/</guid><description>Digital Data Transmission (as Maths) Source Alphabet - S = {s1, s1, &amp;hellip;, sq} of q symbols Code Alphabet A, consisting of r symbols The radix r is the number of symbols in the code alphabet Probabilities p_i = P(S_i) A code that encodes each symbol s_i by a codeword (string of code symbols) Codewords can be seen as vectors.</description></item><item><title>ISBN Codes</title><link>/post/isbn-codes/</link><pubDate>Tue, 17 Sep 2019 12:20:57 +1000</pubDate><guid>/post/isbn-codes/</guid><description>ISBN ISBN: International Standard Book Number</description></item></channel></rss>